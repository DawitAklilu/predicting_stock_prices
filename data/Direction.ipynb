{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcedf3b",
   "metadata": {},
   "source": [
    "# Predicting Stock Price Direction Using Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aeb583",
   "metadata": {},
   "source": [
    "### Background "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfea77",
   "metadata": {},
   "source": [
    "Stock market trend prediction aims at estimating the future price of stock to enable investors on making informed decisions on their investments. Stock price prediction is a challenging and widely studied problem within a braod range of research sectors including finance, mathematics, computer science, history, and economics. Due to its dynamic, non-statiory, and high volatility, It is impossible to predict stock price with the application of regression models and simple time-sieries. Financial institutions and traders have developed models to try to beat the market, yet rarely has anyone ahcieved higher than average returns on investments. For this reason, the challenge of stcok forecasting continues to appeal among institutions, traders, and researchers; even the slightest improvement of percentages can lead to millions of dollars in profit. \n",
    "\n",
    "Some of the well known prediction models continuously researched and optimized include linear and non-linear statistical time series approach such as ARIMA and ARCH. The volatile nature and variance underlying the movement of the stock makes linear models suboptimal and non-linear models have low predictive errors. Machine learning algorithm is another technique that has recently become popular in solving this problem with big data, mathematical and statistical analysis. \n",
    "\n",
    "In this project Support Vector Machine (SVM), a machine learning technqiue, will be used to predict the stock price direction for different stocks from technology sector. Our goal is to use SVM at given time t to predict whether the target stock's price will be higher or lower on day t + m. This prediction model approach is a supervised learning binary classification problem where the input parameters are the stock's volatility and momentum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715b95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pandas_datareader import data as data_reader\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d8d57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>1.156786</td>\n",
       "      <td>1.162679</td>\n",
       "      <td>1.117857</td>\n",
       "      <td>1.130179</td>\n",
       "      <td>0.961916</td>\n",
       "      <td>691992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>1.139107</td>\n",
       "      <td>1.169107</td>\n",
       "      <td>1.124464</td>\n",
       "      <td>1.141786</td>\n",
       "      <td>0.971795</td>\n",
       "      <td>1096810400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>1.151071</td>\n",
       "      <td>1.165179</td>\n",
       "      <td>1.143750</td>\n",
       "      <td>1.151786</td>\n",
       "      <td>0.980306</td>\n",
       "      <td>680433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>1.154821</td>\n",
       "      <td>1.159107</td>\n",
       "      <td>1.130893</td>\n",
       "      <td>1.152679</td>\n",
       "      <td>0.981066</td>\n",
       "      <td>705555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>1.160714</td>\n",
       "      <td>1.243393</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>1.236607</td>\n",
       "      <td>1.052499</td>\n",
       "      <td>2227450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-17</th>\n",
       "      <td>165.089996</td>\n",
       "      <td>165.389999</td>\n",
       "      <td>164.029999</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>41516200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-18</th>\n",
       "      <td>166.100006</td>\n",
       "      <td>167.410004</td>\n",
       "      <td>165.649994</td>\n",
       "      <td>166.470001</td>\n",
       "      <td>166.470001</td>\n",
       "      <td>49923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-19</th>\n",
       "      <td>165.800003</td>\n",
       "      <td>168.160004</td>\n",
       "      <td>165.539993</td>\n",
       "      <td>167.630005</td>\n",
       "      <td>167.630005</td>\n",
       "      <td>47720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-20</th>\n",
       "      <td>166.089996</td>\n",
       "      <td>167.869995</td>\n",
       "      <td>165.559998</td>\n",
       "      <td>166.649994</td>\n",
       "      <td>166.649994</td>\n",
       "      <td>52456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-21</th>\n",
       "      <td>165.050003</td>\n",
       "      <td>166.449997</td>\n",
       "      <td>164.490005</td>\n",
       "      <td>165.020004</td>\n",
       "      <td>165.020004</td>\n",
       "      <td>58311900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4607 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2005-01-03    1.156786    1.162679    1.117857    1.130179    0.961916   \n",
       "2005-01-04    1.139107    1.169107    1.124464    1.141786    0.971795   \n",
       "2005-01-05    1.151071    1.165179    1.143750    1.151786    0.980306   \n",
       "2005-01-06    1.154821    1.159107    1.130893    1.152679    0.981066   \n",
       "2005-01-07    1.160714    1.243393    1.156250    1.236607    1.052499   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-04-17  165.089996  165.389999  164.029999  165.229996  165.229996   \n",
       "2023-04-18  166.100006  167.410004  165.649994  166.470001  166.470001   \n",
       "2023-04-19  165.800003  168.160004  165.539993  167.630005  167.630005   \n",
       "2023-04-20  166.089996  167.869995  165.559998  166.649994  166.649994   \n",
       "2023-04-21  165.050003  166.449997  164.490005  165.020004  165.020004   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2005-01-03   691992000  \n",
       "2005-01-04  1096810400  \n",
       "2005-01-05   680433600  \n",
       "2005-01-06   705555200  \n",
       "2005-01-07  2227450400  \n",
       "...                ...  \n",
       "2023-04-17    41516200  \n",
       "2023-04-18    49923000  \n",
       "2023-04-19    47720200  \n",
       "2023-04-20    52456400  \n",
       "2023-04-21    58311900  \n",
       "\n",
       "[4607 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## here I was checking every csv file to make sure I had enought data for each \n",
    "#stock of interest\n",
    "\n",
    "df = pd.read_csv('AAPL1.csv')   \n",
    "\n",
    "df['Date']= pd.to_datetime(df['Date'])\n",
    "df.index=df['Date']\n",
    "df = df.drop(['Date'],1)\n",
    "df.sort_values(by='Date', ascending = True, inplace = True)\n",
    "\n",
    "\n",
    "df.head()\n",
    "#df.tail()\n",
    "df\n",
    "#df[3370:]\n",
    "#4320*0.22\n",
    "#4320-950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fd0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the stocks of interest (7 in total) using pandas and adjust the size\n",
    "# by indicating start and end dates\n",
    "\n",
    "\n",
    "tickers = ['MSFT1', 'GOOG1', 'AMZN1','AAPL1', 'INTC', 'AMD', 'NVDA']   #given stocks with large volume within ndxt index\n",
    "start_date = datetime.date(2006, 2, 22)\n",
    "end_date = datetime.date(2023, 4, 20)\n",
    "#read in the dataset (csv files)\n",
    "for ticker in tickers:\n",
    "    data = data_reader.DataReader(ticker, 'stooq', start_date, end_date)\n",
    "    data.to_csv(f'{ticker}.csv')\n",
    "    \n",
    "data.sort_values(by='Date', ascending = True, inplace = True)  #sort data by datetime in ascending order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bec124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4320 entries, 2006-02-22 to 2023-04-20\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       4317 non-null   float64\n",
      " 1   High       4317 non-null   float64\n",
      " 2   Low        4317 non-null   float64\n",
      " 3   Close      4317 non-null   float64\n",
      " 4   Adj Close  4317 non-null   float64\n",
      " 5   Volume     4317 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 236.2 KB\n"
     ]
    }
   ],
   "source": [
    "# checking for the datasets size and null values \n",
    "# ndxt (tech) sector dataset\n",
    " \n",
    "ndxtdf = pd.read_csv('ndxt.csv')\n",
    "ndxtdf['Date'] = pd.to_datetime(ndxtdf['Date'])\n",
    "ndxtdf.index = ndxtdf['Date']\n",
    "ndxtdf = ndxtdf.drop(['Date'],1)\n",
    "ndxtdf.sort_values(by = 'Date', ascending = True, inplace = True)\n",
    "\n",
    "ndxtdf.info()             # find the size of data, dtypes for each parameter\n",
    "                        # and the non-null values for each column.\n",
    "ndxtdf = ndxtdf.dropna()   # drop the data with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndxtdf  ##because the tech sector starts from 2006-02-22 goes to, 2023-04-20\\\n",
    "#all other stock companies should be customized in size equally.\n",
    "print(0.22 * len(ndxtdf))\n",
    "print(len(data))\n",
    "4320-950   ## = 3370 for 70% train (split index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate price volatility array given company\n",
    "daysAhead = 1\n",
    "def calcPriceVolatility(numDays, priceArray):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    numDays: number of days from the test data\n",
    "    priceArray: Closing price (used for y)\n",
    "    \n",
    "    Outputs:\n",
    "    calculated Volatility array for the target stock closing price\n",
    "    \n",
    "    \"\"\"\n",
    "    global daysAhead\n",
    "    # make price volatility array\n",
    "    volatilityArray = []\n",
    "    movingVolatilityArray = []\n",
    "    for i in range(1, numDays+1):\n",
    "        percentChange = 100 * (priceArray[i] - priceArray[i-1]) / priceArray[i-1]\n",
    "        movingVolatilityArray.append(percentChange)\n",
    "    volatilityArray.append(np.mean(movingVolatilityArray))\n",
    "    for i in range(numDays + 1, len(priceArray) - daysAhead):\n",
    "        del movingVolatilityArray[0]\n",
    "        percentChange = 100 * (priceArray[i] - priceArray[i-1]) / priceArray[i-1]\n",
    "        movingVolatilityArray.append(percentChange)\n",
    "        volatilityArray.append(np.mean(movingVolatilityArray))\n",
    "    \n",
    "    return volatilityArray\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMomentum(numDays, priceArray):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    numDays: number of days from the test data\n",
    "    priceArray: Closing price (used for y)\n",
    "    \n",
    "    Outputs:\n",
    "    calculated momentum array for the target stock closing price\n",
    "    \n",
    "    \"\"\"\n",
    "    global daysAhead\n",
    "    # now calculate momentum\n",
    "    momentumArray = []\n",
    "    movingMomentumArray = []\n",
    "    for i in range(1, numDays + 1):\n",
    "        movingMomentumArray.append(1 if priceArray[i] > priceArray[i-1] else -1)\n",
    "    momentumArray.append(np.mean(movingMomentumArray))\n",
    "    for i in range(numDays+1, len(priceArray) - daysAhead):\n",
    "        del movingMomentumArray[0]\n",
    "        movingMomentumArray.append(1 if priceArray[i] > priceArray[i-1] else -1)\n",
    "        momentumArray.append(np.mean(movingMomentumArray))\n",
    "\n",
    "    return momentumArray\n",
    "len(calcMomentum(1, data['Close']))\n",
    "#len(df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModelAndPredict(numDays,sectorVolatility, sectorMomentum, splitNumber):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    numDays: number days of stock price used for calculating volatility, momentum\n",
    "    and developing the model\n",
    "    \n",
    "    SectorVolatility: The price volatility for the sector dataset (tech) will be\n",
    "    calculated\n",
    "    \n",
    "    SectorMomentum: The momentum of th sector dataset closing price will be \n",
    "    calculated using functions with designated formulas.\n",
    "    \n",
    "    splitNumber: The index or date at which the test_split will be initialized \n",
    "    (~20% test, 80% train)\n",
    "        \n",
    "        Returns:\n",
    "        The SVM model's score, and true/false statement for the direction prediction.\n",
    "        With this binary classification problem, a -1 will designate to the price\n",
    "        going down and 1 for a price going up.\n",
    "    \"\"\"\n",
    "    \n",
    "    global data\n",
    "    global daysAhead\n",
    "    \n",
    "    # get price volatility and momentum for this company\n",
    "    companyData = data      #AMZN historical data\n",
    "    companyPrices = list(companyData['Close'])\n",
    "\n",
    "    volatilityArray = calcPriceVolatility(numDays, companyPrices)\n",
    "    momentumArray = calcMomentum(numDays, companyPrices)\n",
    "\n",
    "    splitIndex = (splitNumber - numDays)\n",
    "    \n",
    "    # since they are different lengths, find the min length\n",
    "    if len(volatilityArray) > len(sectorVolatility):\n",
    "        difference = len(volatilityArray) - len(sectorVolatility)\n",
    "        del volatilityArray[:difference]\n",
    "        del momentumArray[:difference]\n",
    "\n",
    "    elif len(sectorVolatility) > len(volatilityArray):\n",
    "        difference = len(sectorVolatility) - len(volatilityArray)\n",
    "        del sectorVolatility[:difference]\n",
    "        del sectorMomentum[:difference]\n",
    "    \n",
    "    # create the feature vectors X\n",
    "    X = np.transpose(np.array([volatilityArray, momentumArray,\\\n",
    "                               sectorVolatility, sectorMomentum]))\n",
    "    #print(X)\n",
    "    # create the feature vectors Y\n",
    "    Y = []\n",
    "    for i in range(numDays, len(companyPrices) - daysAhead):\n",
    "        Y.append(1 if companyPrices[i+daysAhead] > companyPrices[i] else -1)\n",
    "    #print (\"len(Y):\",len(Y))\n",
    "\n",
    "    # fix the length of Y if necessary\n",
    "    if len(Y) > len(X):\n",
    "        #print ('fixing length of Y: here2')\n",
    "        difference = len(Y) - len(X)\n",
    "        del Y[:difference]\n",
    "\n",
    "    # split into training and testing sets\n",
    "    X_train = np.array(X[0:splitIndex]).astype('float64')\n",
    "    X_test = np.array(X[splitIndex:]).astype('float64')\n",
    "    y_train = np.array(Y[0:splitIndex]).astype('float64')\n",
    "    y_test = np.array(Y[splitIndex:]).astype('float64')\n",
    "\n",
    "    # fit the model and calculate its accuracy\n",
    "    rbf_svm = svm.SVC(kernel='rbf')\n",
    "    rbf_svm.fit(X_train, y_train)\n",
    "    score = rbf_svm.score(X_test, y_test)\n",
    "    \n",
    "    #Find and print the actual and predicted direction \n",
    "    predicted_direction = rbf_svm.predict(X_test)[0]\n",
    "    print(rbf_svm.predict(X_test)[0])\n",
    "    actual_direction = companyPrices[splitIndex] - companyPrices[splitIndex - 1]\n",
    "    print(companyPrices[splitIndex - 1], companyPrices[splitIndex])\n",
    "    \n",
    "    true_pred = False\n",
    "    \n",
    "    #Show and store the prediction accuracy with True/Flase statements. \n",
    "    if (predicted_direction < 0 and actual_direction < 0) or\\\n",
    "       (predicted_direction > 0 and actual_direction > 0) or\\\n",
    "        (predicted_direction == actual_direction):\n",
    "        print('Correct direction')\n",
    "        true_pred = True\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Wrong direction')\n",
    "  \n",
    "    return (score, true_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97301376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    global data\n",
    "\n",
    "    # find the list of companies\n",
    "    permnoList = tickers\n",
    "\n",
    "    # read the tech sector data\n",
    "    ndxtdf = pd.read_csv('ndxt.csv')\n",
    "    ndxtdf['Date'] = pd.to_datetime(ndxtdf['Date'])\n",
    "    ndxtdf.index = ndxtdf['Date']\n",
    "    ndxtdf = ndxtdf.drop(['Date'],1)\n",
    "    ndxtdf.sort_values(by = 'Date', ascending = True, inplace = True)\n",
    "    ndxtdf = ndxtdf.dropna()\n",
    "\n",
    "    ndxtPrices = np.array(ndxtdf['Close'])\n",
    "    startOfTwelve =  3370  \n",
    "    \n",
    "    pred_effic = []\n",
    "    while startOfTwelve < 3371:    #1520:  #4559: 3461, 3466, 3476\n",
    "    # find when 2011 starts (0.7 = train)\n",
    "    #startOfTwelve = 4557\n",
    "\n",
    "    # we want to predict where it will be on the next day based on X days previous\n",
    "        numDaysArray = [5, 10, 20, 90, 270] # day, week, month, quarter, year\n",
    "        numDaysArrat = np.array(numDaysArray)\n",
    "        predictionDict = {}\n",
    "\n",
    "    \n",
    "    #new lists added 4/16/23 by NA\n",
    " #   numDayIndex_list = []\n",
    " #   meanAccuracy_list = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    # iterate over combinations of n_1 and n_2 and find prediction accuracies\n",
    "        for numDayIndex in numDaysArray:\n",
    "            for numDayStock in numDaysArray:\n",
    "                ndxtVolatilityArray = calcPriceVolatility(numDayIndex, ndxtPrices)\n",
    "                ndxtMomentumArray = calcMomentum(numDayIndex, ndxtPrices)\n",
    "                predictionForGivenNumDaysDict = {}\n",
    "\n",
    "                for permno in permnoList:\n",
    "                #if permno in companiesNotFull:\n",
    "                #continue\n",
    "                    #print (\"stock:\", permno)\n",
    "                    percentage, true_false = makeModelAndPredict(numDayStock,ndxtVolatilityArray,ndxtMomentumArray,startOfTwelve)\n",
    "                    predictionForGivenNumDaysDict[permno] = percentage\n",
    "                    pred_effic.append(true_false)\n",
    "\n",
    "                predictionAccuracies = list(predictionForGivenNumDaysDict.values())\n",
    "                meanAccuracy = np.mean(predictionAccuracies)\n",
    "                print(numDayIndex, numDayStock, meanAccuracy)\n",
    "                #plt.plot(numDayIndex,meanAccuracy)\n",
    "                maxIndex = max(predictionForGivenNumDaysDict, key=predictionForGivenNumDaysDict.get)\n",
    "                maxAccuracy = (maxIndex, predictionForGivenNumDaysDict[maxIndex])\n",
    "                minIndex = min(predictionForGivenNumDaysDict, key=predictionForGivenNumDaysDict.get)\n",
    "                minAccuracy = (minIndex, predictionForGivenNumDaysDict[minIndex])\n",
    "                median = np.median(predictionAccuracies)\n",
    "\n",
    "    \n",
    "                numDaysTuple = (numDayIndex, numDayStock)\n",
    "                predictionDict[numDaysTuple] = {'mean':meanAccuracy, 'max':predictionForGivenNumDaysDict[maxIndex], 'min':predictionForGivenNumDaysDict[minIndex], 'median':median }\n",
    "    \n",
    "        sortedTuples = sorted(predictionDict.keys())\n",
    "        #print(sortedTuples)\n",
    "        for numDaysTuple in sortedTuples:\n",
    "            #print (\"%s:\\t %s\\n\" % (numDaysTuple, predictionDict[numDaysTuple]))\n",
    "            sumStats = predictionDict[numDaysTuple]\n",
    "            #print (\"& %d & %d & %f & %f & %f & %f \\\\\\\\\\n\" % (numDaysTuple[0], numDaysTuple[1], sumStats['mean'], sumStats['median'], sumStats['max'], sumStats['min']))\n",
    "    \n",
    "            #d = {'n1': [numDaysTuple[0]], 'n2': [numDaysTuple[1]], 'mean': [sumStats['mean']], 'median': [sumStats['median']],'max': [sumStats['max']],'min': [sumStats['min']]}\n",
    "            #df1 = pd.DataFrame(data = d)\n",
    "        #print(df1)\n",
    "            \n",
    "        #return df1\n",
    "        startOfTwelve += 1\n",
    "        \n",
    "    return pred_effic\n",
    "                #new code added on 4/16/23 by NA \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    new_var = main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "## removed numday 405 for this iteration\n",
    "\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"10 iterations, m_days = 405\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "true_ = []\n",
    "print(len(new_var))\n",
    "for var in new_var:\n",
    "    if var == True:\n",
    "        #print(len(new_var))\n",
    "        true_.append(var)\n",
    "        \n",
    "len(true_)/1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "## added numday 405 for this iteration\n",
    "\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"1 iterations, m_days = 405\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "true_ = []\n",
    "print(len(new_var))\n",
    "for var in new_var:\n",
    "    if var == True:\n",
    "        #print(len(new_var))\n",
    "        true_.append(var)\n",
    "        \n",
    "len(true_)/252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc31af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"10 iterations, m_days = 1\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "true_ = []\n",
    "print(len(new_var))\n",
    "for var in new_var:\n",
    "    if var == True:\n",
    "        #print(len(new_var))\n",
    "        true_.append(var)\n",
    "        \n",
    "len(true_)/1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"10 iterations, m_days = 5\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "true_ = []\n",
    "print(len(new_var))\n",
    "for var in new_var:\n",
    "    if var == True:\n",
    "        #print(len(new_var))\n",
    "        true_.append(var)\n",
    "        \n",
    "len(true_)/1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"10 iterations, m_days = 10\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "true_ = []\n",
    "print(len(new_var))\n",
    "for var in new_var:\n",
    "    if var == True:\n",
    "        #print(len(new_var))\n",
    "        true_.append(var)\n",
    "        \n",
    "len(true_)/1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 iterations # MSFT', 'GOOG', 'AMZN','AAPL', 'INTC', 'AMD', 'NVDA\n",
    "pd.Series(new_var).value_counts().plot.bar(color = ('teal','teal'))\n",
    "plt.title(\"10 iterations, m_days = 20\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9155e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result1 = pd.read_excel(\"svm_results.xlsx\", usecols = (0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f991a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result1[:149]  #We only need the data up to m = 270\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the trend of mean prediction accuracy for each parameter m\n",
    "\n",
    "x_ax = [1, 5, 10, 20, 90, 270]      # parameter m\n",
    "y_ax = [0.5296, 0.573, 0.5813, 0.6285, 0.696792, 0.69799052]   # mean accuracy\n",
    "\n",
    "plt.scatter(x_ax, y_ax, color = 'b')\n",
    "plt.plot(x_ax, y_ax, color = 'r')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.xlabel('m_days')\n",
    "plt.ylabel('Mean prediction accuracy')\n",
    "plt.title('Mean Prediction Accuracy for each parameter m')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar plot for each m parameter showing mean accuracy for n1,n2\n",
    "\n",
    "\n",
    "#set the n1,n2 to string to get fixed x_ax labels\n",
    "df_result = df_result.astype({'n1': str, 'n2':str})\n",
    "\n",
    "#data for m = 270\n",
    "m_27msk = df_result['m'] == 270\n",
    "m_27df = df_result[m_27msk] \n",
    "\n",
    "#plot the bar chart\n",
    "import plotly.express as px\n",
    "df = m_27df\n",
    "fig = px.bar(df, x=\"n1\", y=\"mean\",\n",
    "             color='n2', barmode='group',\n",
    "             height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16c1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
